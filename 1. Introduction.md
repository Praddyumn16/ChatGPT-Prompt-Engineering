# Introduction
There are mainly 2 types of LLM's:

**1. Base LLM** - which predicts next word to follow based on some text training data.
But it fails on questions like "What is the capital of France?" for which it might respond: "What is the France's largest city" because articles on the internet could possibly be a list of questions related to France.

**2. Instruction tuned LLM** - Here, we start with a Base LLM and further fine tune it based on some inputs and outputs which are instructions and good attempt to follow those instructions. Then, we further refine it based on RLHF (Reinforcement Learning with Human Feedback)

For example, if you say: "Write me something about Alan Turing", it would be better if you specify:
- whether you want to know about his personal or professional life
- what should be the tone of the text, whether it's being written by a friend or a professional reporter
- whether there's any text which they should read in advance to get an idea before writing this text

**Usage of OpenAI API:** There are mainly 3 roles for an object - **system**, **user** and **assistant**. Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.<br/>
The system role help you set the tone of responses that you want to receive.

```python
import openai

openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```
